{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8500878-f611-4fb2-a795-ddc51f55a5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Step is to obtain the data from the census website\n",
    "# After some research concluded that B08303 is the correct data set to use (it is titled \"Travel Time to Work\"\n",
    "# The basis for using this dataset is the obvious inverse relationship between Telework and Commute Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1523d13b-6f8a-45a4-b533-04f59475f111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We begin with the 2023 and 2022 \"ACS 1-Year Estimates Detailed Tables\".\n",
    "# The weblinks are: https://data.census.gov/table/ACSDT1Y2023.B08303?g=010XX00US$3300000 for 2023\n",
    "# The link is the census website (data.census.gov), \"Table\" because we want the option to download\n",
    "# ACSDT1, I have learned, stands for American Community Survey (ACS) Detailed Tables - perhaps data tables - for 1 year\n",
    "#  The last 5 year was issued in 2022 so the most recent data in 2023 is single year\n",
    "# B08303 refers to the \"Travel to Work Data\" which for historic reasons is known as B08303\n",
    "# This was then set up by geography - hence the \"g=\", and then the 010 is a placeholder, and XX00US is a placeholder for all States\n",
    "#  33000000 appears to be by metropolitan area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0552b5b7-72ed-4b15-820e-58b94f5707d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The given the small number of files we need to download this can be done manually\n",
    "# But to show that it CAN be done automatically used Claude to create some code which will use an API (secret under env)\n",
    "# to download data for each year and then to create csv files with that data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f589206-4526-4130-91e0-b289b68c2dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "085188d9-039a-4eb8-8a35-4162a37ecb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for 2010...\n",
      "Data for 2010 saved to /Users/baruchgottesman/AIClass/ai-project-2/Commute_Time_By_Metro_Area_2010.csv\n",
      "\n",
      "Fetching data for 2011...\n",
      "Attempt 1 failed for year 2011. Error: HTTPSConnectionPool(host='api.census.gov', port=443): Read timed out. (read timeout=30)\n",
      "Retrying in 5 seconds...\n",
      "Attempt 2 failed for year 2011. Error: HTTPSConnectionPool(host='api.census.gov', port=443): Read timed out. (read timeout=30)\n",
      "Retrying in 5 seconds...\n",
      "Data for 2011 saved to /Users/baruchgottesman/AIClass/ai-project-2/Commute_Time_By_Metro_Area_2011.csv\n",
      "\n",
      "Fetching data for 2012...\n",
      "Data for 2012 saved to /Users/baruchgottesman/AIClass/ai-project-2/Commute_Time_By_Metro_Area_2012.csv\n",
      "\n",
      "Fetching data for 2013...\n",
      "Data for 2013 saved to /Users/baruchgottesman/AIClass/ai-project-2/Commute_Time_By_Metro_Area_2013.csv\n",
      "\n",
      "Fetching data for 2014...\n",
      "Data for 2014 saved to /Users/baruchgottesman/AIClass/ai-project-2/Commute_Time_By_Metro_Area_2014.csv\n",
      "\n",
      "Fetching data for 2015...\n",
      "Data for 2015 saved to /Users/baruchgottesman/AIClass/ai-project-2/Commute_Time_By_Metro_Area_2015.csv\n",
      "\n",
      "Fetching data for 2016...\n",
      "Data for 2016 saved to /Users/baruchgottesman/AIClass/ai-project-2/Commute_Time_By_Metro_Area_2016.csv\n",
      "\n",
      "Fetching data for 2017...\n",
      "Data for 2017 saved to /Users/baruchgottesman/AIClass/ai-project-2/Commute_Time_By_Metro_Area_2017.csv\n",
      "\n",
      "Fetching data for 2018...\n",
      "Data for 2018 saved to /Users/baruchgottesman/AIClass/ai-project-2/Commute_Time_By_Metro_Area_2018.csv\n",
      "\n",
      "Fetching data for 2019...\n",
      "Data for 2019 saved to /Users/baruchgottesman/AIClass/ai-project-2/Commute_Time_By_Metro_Area_2019.csv\n",
      "\n",
      "Fetching data for 2020...\n",
      "Attempt 1 failed for year 2020. Error: 404 Client Error:  for url: https://api.census.gov/data/2020/acs/acs1?get=NAME%2CB08303_001E%2CB08303_002E%2CB08303_003E%2CB08303_004E%2CB08303_005E%2CB08303_006E%2CB08303_007E%2CB08303_008E%2CB08303_009E%2CB08303_010E%2CB08303_011E%2CB08303_012E%2CB08303_013E&for=metropolitan+statistical+area%2Fmicropolitan+statistical+area%3A%2A&key=07cb310f97963cda0bb537312bd7fdb13c438e72\n",
      "Retrying in 5 seconds...\n",
      "Attempt 2 failed for year 2020. Error: 404 Client Error:  for url: https://api.census.gov/data/2020/acs/acs1?get=NAME%2CB08303_001E%2CB08303_002E%2CB08303_003E%2CB08303_004E%2CB08303_005E%2CB08303_006E%2CB08303_007E%2CB08303_008E%2CB08303_009E%2CB08303_010E%2CB08303_011E%2CB08303_012E%2CB08303_013E&for=metropolitan+statistical+area%2Fmicropolitan+statistical+area%3A%2A&key=07cb310f97963cda0bb537312bd7fdb13c438e72\n",
      "Retrying in 5 seconds...\n",
      "Attempt 3 failed for year 2020. Error: 404 Client Error:  for url: https://api.census.gov/data/2020/acs/acs1?get=NAME%2CB08303_001E%2CB08303_002E%2CB08303_003E%2CB08303_004E%2CB08303_005E%2CB08303_006E%2CB08303_007E%2CB08303_008E%2CB08303_009E%2CB08303_010E%2CB08303_011E%2CB08303_012E%2CB08303_013E&for=metropolitan+statistical+area%2Fmicropolitan+statistical+area%3A%2A&key=07cb310f97963cda0bb537312bd7fdb13c438e72\n",
      "Failed to fetch data for 2020 after 3 attempts.\n",
      "Skipping 2020 due to persistent errors.\n",
      "\n",
      "Fetching data for 2021...\n",
      "Data for 2021 saved to /Users/baruchgottesman/AIClass/ai-project-2/Commute_Time_By_Metro_Area_2021.csv\n",
      "\n",
      "Fetching data for 2022...\n",
      "Data for 2022 saved to /Users/baruchgottesman/AIClass/ai-project-2/Commute_Time_By_Metro_Area_2022.csv\n",
      "\n",
      "Fetching data for 2023...\n",
      "Data for 2023 saved to /Users/baruchgottesman/AIClass/ai-project-2/Commute_Time_By_Metro_Area_2023.csv\n",
      "\n",
      "Fetching data for 2024...\n",
      "Attempt 1 failed for year 2024. Error: 404 Client Error:  for url: https://api.census.gov/data/2024/acs/acs1?get=NAME%2CB08303_001E%2CB08303_002E%2CB08303_003E%2CB08303_004E%2CB08303_005E%2CB08303_006E%2CB08303_007E%2CB08303_008E%2CB08303_009E%2CB08303_010E%2CB08303_011E%2CB08303_012E%2CB08303_013E&for=metropolitan+statistical+area%2Fmicropolitan+statistical+area%3A%2A&key=07cb310f97963cda0bb537312bd7fdb13c438e72\n",
      "Retrying in 5 seconds...\n",
      "Attempt 2 failed for year 2024. Error: 404 Client Error:  for url: https://api.census.gov/data/2024/acs/acs1?get=NAME%2CB08303_001E%2CB08303_002E%2CB08303_003E%2CB08303_004E%2CB08303_005E%2CB08303_006E%2CB08303_007E%2CB08303_008E%2CB08303_009E%2CB08303_010E%2CB08303_011E%2CB08303_012E%2CB08303_013E&for=metropolitan+statistical+area%2Fmicropolitan+statistical+area%3A%2A&key=07cb310f97963cda0bb537312bd7fdb13c438e72\n",
      "Retrying in 5 seconds...\n",
      "Attempt 3 failed for year 2024. Error: 404 Client Error:  for url: https://api.census.gov/data/2024/acs/acs1?get=NAME%2CB08303_001E%2CB08303_002E%2CB08303_003E%2CB08303_004E%2CB08303_005E%2CB08303_006E%2CB08303_007E%2CB08303_008E%2CB08303_009E%2CB08303_010E%2CB08303_011E%2CB08303_012E%2CB08303_013E&for=metropolitan+statistical+area%2Fmicropolitan+statistical+area%3A%2A&key=07cb310f97963cda0bb537312bd7fdb13c438e72\n",
      "Failed to fetch data for 2024 after 3 attempts.\n",
      "Skipping 2024 due to persistent errors.\n",
      "\n",
      "Global data for all years saved to /Users/baruchgottesman/AIClass/ai-project-2/Commute_Time_By_Metro_Area_All_Years.csv\n",
      "Data fetching complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from requests.exceptions import RequestException\n",
    "\n",
    "# Load environment variables from the specific .env file\n",
    "load_dotenv('CENSUS_API_KEY.env')\n",
    "\n",
    "# Get API key from environment variable\n",
    "api_key = os.getenv('CENSUS_API_KEY')\n",
    "\n",
    "# Define human-readable column names\n",
    "column_names = {\n",
    "    'NAME': 'Metro Area',\n",
    "    'B08303_001E': 'Total',\n",
    "    'B08303_002E': 'Less than 5 minutes',\n",
    "    'B08303_003E': '5 to 9 minutes',\n",
    "    'B08303_004E': '10 to 14 minutes',\n",
    "    'B08303_005E': '15 to 19 minutes',\n",
    "    'B08303_006E': '20 to 24 minutes',\n",
    "    'B08303_007E': '25 to 29 minutes',\n",
    "    'B08303_008E': '30 to 34 minutes',\n",
    "    'B08303_009E': '35 to 39 minutes',\n",
    "    'B08303_010E': '40 to 44 minutes',\n",
    "    'B08303_011E': '45 to 59 minutes',\n",
    "    'B08303_012E': '60 to 89 minutes',\n",
    "    'B08303_013E': '90 or more minutes'\n",
    "}\n",
    "\n",
    "def fetch_and_save_data(year, max_retries=3, delay=5):\n",
    "    # Census API endpoint\n",
    "    api_url = f\"https://api.census.gov/data/{year}/acs/acs1\"\n",
    "\n",
    "    # Parameters for the API request\n",
    "    params = {\n",
    "        \"get\": \",\".join(column_names.keys()),\n",
    "        \"for\": \"metropolitan statistical area/micropolitan statistical area:*\",\n",
    "        \"key\": api_key\n",
    "    }\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Make the API request\n",
    "            response = requests.get(api_url, params=params, timeout=30)\n",
    "            response.raise_for_status()  # Raise an exception for bad status codes\n",
    "\n",
    "            # Process the data\n",
    "            data = response.json()\n",
    "            df = pd.DataFrame(data[1:], columns=data[0])\n",
    "            \n",
    "            # Rename columns to human-readable names\n",
    "            df = df.rename(columns=column_names)\n",
    "            \n",
    "            # Convert numeric columns to integers, replacing non-numeric values with NaN\n",
    "            numeric_columns = df.columns[1:-1]  # All columns except 'Metro Area' and the last one\n",
    "            for col in numeric_columns:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            \n",
    "            # Replace NaN with 0 or handle as needed\n",
    "            df[numeric_columns] = df[numeric_columns].fillna(0).astype(int)\n",
    "            \n",
    "            # Remove the metropolitan statistical area/micropolitan statistical area code column\n",
    "            df = df.drop(columns=['metropolitan statistical area/micropolitan statistical area'])\n",
    "            \n",
    "            # Add a Year column\n",
    "            df['Year'] = year\n",
    "            \n",
    "            # Save to CSV\n",
    "            output_file = f'Commute_Time_By_Metro_Area_{year}.csv'\n",
    "            df.to_csv(output_file, index=False)\n",
    "            print(f\"Data for {year} saved to {os.path.abspath(output_file)}\")\n",
    "            return df\n",
    "\n",
    "        except RequestException as e:\n",
    "            print(f\"Attempt {attempt + 1} failed for year {year}. Error: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"Retrying in {delay} seconds...\")\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                print(f\"Failed to fetch data for {year} after {max_retries} attempts.\")\n",
    "                return None\n",
    "\n",
    "# Years to fetch data for\n",
    "years = range(2010, 2025)  # 2010 to 2024\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for year in years:\n",
    "    print(f\"Fetching data for {year}...\")\n",
    "    year_data = fetch_and_save_data(year)\n",
    "    if year_data is not None:\n",
    "        all_data.append(year_data)\n",
    "    else:\n",
    "        print(f\"Skipping {year} due to persistent errors.\")\n",
    "    print()  # Add a blank line for readability\n",
    "    time.sleep(2)  # Add a 2-second delay between years to avoid overwhelming the API\n",
    "\n",
    "# Combine all data into a single DataFrame\n",
    "if all_data:\n",
    "    global_df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    # Save the global CSV\n",
    "    global_csv = 'Commute_Time_By_Metro_Area_All_Years.csv'\n",
    "    global_df.to_csv(global_csv, index=False)\n",
    "    print(f\"Global data for all years saved to {os.path.abspath(global_csv)}\")\n",
    "else:\n",
    "    print(\"No data was successfully retrieved for any year.\")\n",
    "\n",
    "print(\"Data fetching complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b743700-cc4f-4b7f-a04f-67917dc8ac52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for top 25 metro areas has been saved to 'Commute_Time_By_Top_25_Metro_Area_All_Years.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('Commute_Time_By_Metro_Area_All_Years.csv')\n",
    "\n",
    "# Group by Metro Area and calculate the average Total\n",
    "metro_averages = df.groupby('Metro Area')['Total'].mean().reset_index()\n",
    "\n",
    "# Sort by Total in descending order and select top 25\n",
    "top_25_metros = metro_averages.sort_values('Total', ascending=False).head(25)\n",
    "\n",
    "# Get the list of top 25 metro areas\n",
    "top_25_metro_list = top_25_metros['Metro Area'].tolist()\n",
    "\n",
    "# Filter the original dataframe to include only the top 25 metro areas\n",
    "top_25_data = df[df['Metro Area'].isin(top_25_metro_list)]\n",
    "\n",
    "# Sort the data by Metro Area and any other relevant columns (e.g., year if present)\n",
    "top_25_data = top_25_data.sort_values(['Metro Area'])\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "top_25_data.to_csv('Commute_Time_By_Top_25_Metro_Area_All_Years.csv', index=False)\n",
    "\n",
    "print(f\"Data for top 25 metro areas has been saved to 'Commute_Time_By_Top_25_Metro_Area_All_Years.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0858dfc-9fed-447c-81b2-35714d739390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage data has been saved to 'Commute_Time_By_Top_25_Metro_Area_All_Years_Percentage.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('Commute_Time_By_Top_25_Metro_Area_All_Years.csv')\n",
    "\n",
    "# List of columns to convert to percentages\n",
    "time_columns = [\n",
    "    \"Less than 5 minutes\", \"5 to 9 minutes\", \"10 to 14 minutes\",\n",
    "    \"15 to 19 minutes\", \"20 to 24 minutes\", \"25 to 29 minutes\",\n",
    "    \"30 to 34 minutes\", \"35 to 39 minutes\", \"40 to 44 minutes\",\n",
    "    \"45 to 59 minutes\", \"60 to 89 minutes\", \"90 or more minutes\"\n",
    "]\n",
    "\n",
    "# Calculate percentages\n",
    "for col in time_columns:\n",
    "    df[col] = (df[col] / df['Total'] * 100).round(5)\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "df.to_csv('Commute_Time_By_Top_25_Metro_Area_All_Years_Percentage.csv', index=False)\n",
    "\n",
    "print(\"Percentage data has been saved to 'Commute_Time_By_Top_25_Metro_Area_All_Years_Percentage.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfb1772d-51f0-4d4f-8966-a02796c020ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What this Code has Done is create a csv/Dataframe that is called \"Commute_Time_By_Top_25_Metro_Areas_All_Years.csv\"\n",
    "# For the top 25 by size it contains for each year from 2010 through 2024 (2023 actually, because '24 data not available) it has the\n",
    "# commute times brokwn down into different 5/10 minute categories\n",
    "#  To make this usable, we're going to then ask it to convert the raw numbers into percentages so we can see how\n",
    "# much of a particular population is doing very long commutes, how many slower commutes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "143dbe56-0652-4a23-81c5-efc892de7349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphs have been saved in the 'metro_graphs' directory.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('Commute_Time_By_Top_25_Metro_Area_All_Years_Percentage.csv')\n",
    "\n",
    "# Ensure 'Year' column exists\n",
    "if 'Year' not in df.columns:\n",
    "    print(\"Error: 'Year' column not found in the CSV file.\")\n",
    "    exit()\n",
    "\n",
    "# List of time categories\n",
    "time_categories = [\n",
    "    \"Less than 5 minutes\", \"5 to 9 minutes\", \"10 to 14 minutes\",\n",
    "    \"15 to 19 minutes\", \"20 to 24 minutes\", \"25 to 29 minutes\",\n",
    "    \"30 to 34 minutes\", \"35 to 39 minutes\", \"40 to 44 minutes\",\n",
    "    \"45 to 59 minutes\", \"60 to 89 minutes\", \"90 or more minutes\"\n",
    "]\n",
    "\n",
    "# Create a directory to store the graphs\n",
    "if not os.path.exists('metro_graphs'):\n",
    "    os.makedirs('metro_graphs')\n",
    "\n",
    "# Function to create a graph for a single metro area\n",
    "def create_metro_graph(metro_data, metro_name):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for category in time_categories:\n",
    "        plt.plot(metro_data['Year'], metro_data[category], label=category)\n",
    "    \n",
    "    plt.title(f'Commute Time Percentages for {metro_name} (2005-2018)')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Percentage')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'metro_graphs/{metro_name.replace(\"/\", \"_\")}_commute_times.png')\n",
    "    plt.close()\n",
    "\n",
    "# Group by Metro Area and create graphs\n",
    "for metro_area, group in df.groupby('Metro Area'):\n",
    "    create_metro_graph(group, metro_area)\n",
    "\n",
    "print(\"Graphs have been saved in the 'metro_graphs' directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
