{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8500878-f611-4fb2-a795-ddc51f55a5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Step is to obtain the data from the census website\n",
    "# After some research concluded that B08303 is the correct data set to use (it is titled \"Travel Time to Work\"\n",
    "# The basis for using this dataset is the obvious inverse relationship between Telework and Commute Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1523d13b-6f8a-45a4-b533-04f59475f111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We begin with the 2023 and 2022 \"ACS 1-Year Estimates Detailed Tables\".\n",
    "# The weblinks are: https://data.census.gov/table/ACSDT1Y2023.B08303?g=010XX00US$3300000 for 2023\n",
    "# The link is the census website (data.census.gov), \"Table\" because we want the option to download\n",
    "# ACSDT1, I have learned, stands for American Community Survey (ACS) Detailed Tables - perhaps data tables - for 1 year\n",
    "#  The last 5 year was issued in 2022 so the most recent data in 2023 is single year\n",
    "# B08303 refers to the \"Travel to Work Data\" which for historic reasons is known as B08303\n",
    "# This was then set up by geography - hence the \"g=\", and then the 010 is a placeholder, and XX00US is a placeholder for all States\n",
    "#  33000000 appears to be by metropolitan area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0552b5b7-72ed-4b15-820e-58b94f5707d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The given the small number of files we need to download this can be done manually\n",
    "# But to show that it CAN be done automatically used Claude to create some code which will use an API (secret under env)\n",
    "# to download data for each year and then to create csv files with that data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f589206-4526-4130-91e0-b289b68c2dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "085188d9-039a-4eb8-8a35-4162a37ecb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for 2010...\n",
      "Data for 2010 saved to /Users/baruchgottesman/ai-project-2/Commute_Time_By_Metro_Area_2010.csv\n",
      "\n",
      "Fetching data for 2011...\n",
      "Data for 2011 saved to /Users/baruchgottesman/ai-project-2/Commute_Time_By_Metro_Area_2011.csv\n",
      "\n",
      "Fetching data for 2012...\n",
      "Data for 2012 saved to /Users/baruchgottesman/ai-project-2/Commute_Time_By_Metro_Area_2012.csv\n",
      "\n",
      "Fetching data for 2013...\n",
      "Data for 2013 saved to /Users/baruchgottesman/ai-project-2/Commute_Time_By_Metro_Area_2013.csv\n",
      "\n",
      "Fetching data for 2014...\n",
      "Data for 2014 saved to /Users/baruchgottesman/ai-project-2/Commute_Time_By_Metro_Area_2014.csv\n",
      "\n",
      "Fetching data for 2015...\n",
      "Data for 2015 saved to /Users/baruchgottesman/ai-project-2/Commute_Time_By_Metro_Area_2015.csv\n",
      "\n",
      "Fetching data for 2016...\n",
      "Data for 2016 saved to /Users/baruchgottesman/ai-project-2/Commute_Time_By_Metro_Area_2016.csv\n",
      "\n",
      "Fetching data for 2017...\n",
      "Data for 2017 saved to /Users/baruchgottesman/ai-project-2/Commute_Time_By_Metro_Area_2017.csv\n",
      "\n",
      "Fetching data for 2018...\n",
      "Data for 2018 saved to /Users/baruchgottesman/ai-project-2/Commute_Time_By_Metro_Area_2018.csv\n",
      "\n",
      "Fetching data for 2019...\n",
      "Data for 2019 saved to /Users/baruchgottesman/ai-project-2/Commute_Time_By_Metro_Area_2019.csv\n",
      "\n",
      "Fetching data for 2020...\n",
      "Attempt 1 failed for year 2020. Error: 404 Client Error:  for url: https://api.census.gov/data/2020/acs/acs1?get=NAME%2CB08303_001E%2CB08303_002E%2CB08303_003E%2CB08303_004E%2CB08303_005E%2CB08303_006E%2CB08303_007E%2CB08303_008E%2CB08303_009E%2CB08303_010E%2CB08303_011E%2CB08303_012E%2CB08303_013E&for=metropolitan+statistical+area%2Fmicropolitan+statistical+area%3A%2A\n",
      "Retrying in 5 seconds...\n",
      "Attempt 2 failed for year 2020. Error: 404 Client Error:  for url: https://api.census.gov/data/2020/acs/acs1?get=NAME%2CB08303_001E%2CB08303_002E%2CB08303_003E%2CB08303_004E%2CB08303_005E%2CB08303_006E%2CB08303_007E%2CB08303_008E%2CB08303_009E%2CB08303_010E%2CB08303_011E%2CB08303_012E%2CB08303_013E&for=metropolitan+statistical+area%2Fmicropolitan+statistical+area%3A%2A\n",
      "Retrying in 5 seconds...\n",
      "Attempt 3 failed for year 2020. Error: 404 Client Error:  for url: https://api.census.gov/data/2020/acs/acs1?get=NAME%2CB08303_001E%2CB08303_002E%2CB08303_003E%2CB08303_004E%2CB08303_005E%2CB08303_006E%2CB08303_007E%2CB08303_008E%2CB08303_009E%2CB08303_010E%2CB08303_011E%2CB08303_012E%2CB08303_013E&for=metropolitan+statistical+area%2Fmicropolitan+statistical+area%3A%2A\n",
      "Failed to fetch data for 2020 after 3 attempts.\n",
      "Skipping 2020 due to persistent errors.\n",
      "\n",
      "Fetching data for 2021...\n",
      "Data for 2021 saved to /Users/baruchgottesman/ai-project-2/Commute_Time_By_Metro_Area_2021.csv\n",
      "\n",
      "Fetching data for 2022...\n",
      "Data for 2022 saved to /Users/baruchgottesman/ai-project-2/Commute_Time_By_Metro_Area_2022.csv\n",
      "\n",
      "Fetching data for 2023...\n",
      "Data for 2023 saved to /Users/baruchgottesman/ai-project-2/Commute_Time_By_Metro_Area_2023.csv\n",
      "\n",
      "Fetching data for 2024...\n",
      "Attempt 1 failed for year 2024. Error: 404 Client Error:  for url: https://api.census.gov/data/2024/acs/acs1?get=NAME%2CB08303_001E%2CB08303_002E%2CB08303_003E%2CB08303_004E%2CB08303_005E%2CB08303_006E%2CB08303_007E%2CB08303_008E%2CB08303_009E%2CB08303_010E%2CB08303_011E%2CB08303_012E%2CB08303_013E&for=metropolitan+statistical+area%2Fmicropolitan+statistical+area%3A%2A\n",
      "Retrying in 5 seconds...\n",
      "Attempt 2 failed for year 2024. Error: 404 Client Error:  for url: https://api.census.gov/data/2024/acs/acs1?get=NAME%2CB08303_001E%2CB08303_002E%2CB08303_003E%2CB08303_004E%2CB08303_005E%2CB08303_006E%2CB08303_007E%2CB08303_008E%2CB08303_009E%2CB08303_010E%2CB08303_011E%2CB08303_012E%2CB08303_013E&for=metropolitan+statistical+area%2Fmicropolitan+statistical+area%3A%2A\n",
      "Retrying in 5 seconds...\n",
      "Attempt 3 failed for year 2024. Error: 404 Client Error:  for url: https://api.census.gov/data/2024/acs/acs1?get=NAME%2CB08303_001E%2CB08303_002E%2CB08303_003E%2CB08303_004E%2CB08303_005E%2CB08303_006E%2CB08303_007E%2CB08303_008E%2CB08303_009E%2CB08303_010E%2CB08303_011E%2CB08303_012E%2CB08303_013E&for=metropolitan+statistical+area%2Fmicropolitan+statistical+area%3A%2A\n",
      "Failed to fetch data for 2024 after 3 attempts.\n",
      "Skipping 2024 due to persistent errors.\n",
      "\n",
      "Global data for all years saved to /Users/baruchgottesman/ai-project-2/Commute_Time_By_Metro_Area_All_Years.csv\n",
      "Data fetching complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from requests.exceptions import RequestException\n",
    "\n",
    "# Load environment variables from the specific .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API key from environment variable\n",
    "api_key = os.getenv('CENSUS_API_KEY')\n",
    "\n",
    "# Define human-readable column names\n",
    "column_names = {\n",
    "    'NAME': 'Metro Area',\n",
    "    'B08303_001E': 'Total',\n",
    "    'B08303_002E': 'Less than 5 minutes',\n",
    "    'B08303_003E': '5 to 9 minutes',\n",
    "    'B08303_004E': '10 to 14 minutes',\n",
    "    'B08303_005E': '15 to 19 minutes',\n",
    "    'B08303_006E': '20 to 24 minutes',\n",
    "    'B08303_007E': '25 to 29 minutes',\n",
    "    'B08303_008E': '30 to 34 minutes',\n",
    "    'B08303_009E': '35 to 39 minutes',\n",
    "    'B08303_010E': '40 to 44 minutes',\n",
    "    'B08303_011E': '45 to 59 minutes',\n",
    "    'B08303_012E': '60 to 89 minutes',\n",
    "    'B08303_013E': '90 or more minutes'\n",
    "}\n",
    "\n",
    "def fetch_and_save_data(year, max_retries=3, delay=5):\n",
    "    # Census API endpoint\n",
    "    api_url = f\"https://api.census.gov/data/{year}/acs/acs1\"\n",
    "\n",
    "    # Parameters for the API request\n",
    "    params = {\n",
    "        \"get\": \",\".join(column_names.keys()),\n",
    "        \"for\": \"metropolitan statistical area/micropolitan statistical area:*\",\n",
    "        \"key\": api_key\n",
    "    }\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Make the API request\n",
    "            response = requests.get(api_url, params=params, timeout=30)\n",
    "            response.raise_for_status()  # Raise an exception for bad status codes\n",
    "\n",
    "            # Process the data\n",
    "            data = response.json()\n",
    "            df = pd.DataFrame(data[1:], columns=data[0])\n",
    "            \n",
    "            # Rename columns to human-readable names\n",
    "            df = df.rename(columns=column_names)\n",
    "            \n",
    "            # Convert numeric columns to integers, replacing non-numeric values with NaN\n",
    "            numeric_columns = df.columns[1:-1]  # All columns except 'Metro Area' and the last one\n",
    "            for col in numeric_columns:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            \n",
    "            # Replace NaN with 0 or handle as needed\n",
    "            df[numeric_columns] = df[numeric_columns].fillna(0).astype(int)\n",
    "            \n",
    "            # Remove the metropolitan statistical area/micropolitan statistical area code column\n",
    "            df = df.drop(columns=['metropolitan statistical area/micropolitan statistical area'])\n",
    "            \n",
    "            # Add a Year column\n",
    "            df['Year'] = year\n",
    "            \n",
    "            # Save to CSV\n",
    "            output_file = f'Commute_Time_By_Metro_Area_{year}.csv'\n",
    "            df.to_csv(output_file, index=False)\n",
    "            print(f\"Data for {year} saved to {os.path.abspath(output_file)}\")\n",
    "            return df\n",
    "\n",
    "        except RequestException as e:\n",
    "            print(f\"Attempt {attempt + 1} failed for year {year}. Error: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"Retrying in {delay} seconds...\")\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                print(f\"Failed to fetch data for {year} after {max_retries} attempts.\")\n",
    "                return None\n",
    "\n",
    "# Years to fetch data for\n",
    "years = range(2010, 2025)  # 2010 to 2024\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for year in years:\n",
    "    print(f\"Fetching data for {year}...\")\n",
    "    year_data = fetch_and_save_data(year)\n",
    "    if year_data is not None:\n",
    "        all_data.append(year_data)\n",
    "    else:\n",
    "        print(f\"Skipping {year} due to persistent errors.\")\n",
    "    print()  # Add a blank line for readability\n",
    "    time.sleep(2)  # Add a 2-second delay between years to avoid overwhelming the API\n",
    "\n",
    "# Combine all data into a single DataFrame\n",
    "if all_data:\n",
    "    global_df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    # Save the global CSV\n",
    "    global_csv = 'Commute_Time_By_Metro_Area_All_Years.csv'\n",
    "    global_df.to_csv(global_csv, index=False)\n",
    "    print(f\"Global data for all years saved to {os.path.abspath(global_csv)}\")\n",
    "else:\n",
    "    print(\"No data was successfully retrieved for any year.\")\n",
    "\n",
    "print(\"Data fetching complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7639f0b8-10aa-4ec3-9fb1-1760a219c614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'Commute_Time_By_Metro_Area_All_Years.csv' has been updated with cleaned Metro Area names.\n",
      "       Metro Area\n",
      "0       Aberdeen,\n",
      "1        Abilene,\n",
      "2         Adrian,\n",
      "3       Aguadilla\n",
      "4          Akron,\n",
      "5         Albany,\n",
      "6          Albany\n",
      "7          Albany\n",
      "8    Albertville,\n",
      "9    Albuquerque,\n",
      "10    Alexandria,\n",
      "11       Allegan,\n",
      "12      Allentown\n",
      "13       Altoona,\n",
      "14      Amarillo,\n",
      "15          Ames,\n",
      "16     Anchorage,\n",
      "17      Anderson,\n",
      "18      Anderson,\n",
      "19     Ann Arbor,\n",
      "20       Anniston\n",
      "21      Appleton,\n",
      "22     Asheville,\n",
      "23     Ashtabula,\n",
      "24        Athens,\n",
      "25         Athens\n",
      "26        Atlanta\n",
      "27  Atlantic City\n",
      "28        Auburn,\n",
      "29         Auburn\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "file_name = 'Commute_Time_By_Metro_Area_All_Years.csv'\n",
    "df = pd.read_csv(file_name)\n",
    "\n",
    "# Function to clean up the Metro Area name\n",
    "def clean_metro_name(name):\n",
    "    # Split by dash and take the first part\n",
    "    first_part = name.split('-')[0].strip()\n",
    "    \n",
    "    # Handle multi-word city names (e.g., \"New York\")\n",
    "    words = first_part.split()\n",
    "    if len(words) > 1 and words[1].istitle():\n",
    "        return ' '.join(words[:2])  # Return first two words if second is capitalized\n",
    "    else:\n",
    "        return words[0]  # Otherwise, return just the first word\n",
    "\n",
    "# Apply the cleaning function to the Metro Area column\n",
    "df['Metro Area'] = df['Metro Area'].apply(clean_metro_name)\n",
    "\n",
    "# Save the updated DataFrame back to the same CSV file\n",
    "df.to_csv(file_name, index=False)\n",
    "\n",
    "print(f\"File '{file_name}' has been updated with cleaned Metro Area names.\")\n",
    "\n",
    "# Display the first few rows to verify the changes\n",
    "print(df[['Metro Area']].head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b743700-cc4f-4b7f-a04f-67917dc8ac52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for top 50 metro areas has been saved to 'Commute_Time_By_Top_50_Metro_Area_All_Years.csv'\n",
      "(624, 15)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('Commute_Time_By_Metro_Area_All_Years.csv')\n",
    "\n",
    "# Group by Metro Area and calculate the average Total\n",
    "metro_averages = df.groupby('Metro Area')['Total'].mean().reset_index()\n",
    "\n",
    "# Sort by Total in descending order and select top 50\n",
    "top_50_metros = metro_averages.sort_values('Total', ascending=False).head(50)\n",
    "\n",
    "# Get the list of top 50 metro areas\n",
    "top_50_metro_list = top_50_metros['Metro Area'].tolist()\n",
    "\n",
    "# Filter the original dataframe to include only the top 50 metro areas\n",
    "top_50_data = df[df['Metro Area'].isin(top_50_metro_list)]\n",
    "\n",
    "# Sort the data by Metro Area and any other relevant columns (e.g., year if present)\n",
    "top_50_data = top_50_data.sort_values(['Metro Area'])\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "top_50_data.to_csv('Commute_Time_By_Top_50_Metro_Area_All_Years.csv', index=False)\n",
    "\n",
    "print(f\"Data for top 50 metro areas has been saved to 'Commute_Time_By_Top_50_Metro_Area_All_Years.csv'\")\n",
    "print(top_50_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7d37113e-9a94-4cc0-b579-6a78bc97c8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation complete. New CSV file created.\n",
      "(624, 15)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('Commute_Time_By_Top_50_Metro_Area_All_Years.csv')\n",
    "\n",
    "# Define the columns for each new bucket\n",
    "no_commute_cols = [\"Less than 5 minutes\"]\n",
    "yes_commute_cols = [\n",
    "    \"5 to 9 minutes\", \"10 to 14 minutes\", \"15 to 19 minutes\", \"20 to 24 minutes\",\n",
    "    \"25 to 29 minutes\", \"30 to 34 minutes\", \"35 to 39 minutes\", \"40 to 44 minutes\",\n",
    "    \"45 to 59 minutes\", \"60 to 89 minutes\", \"90 or more minutes\"\n",
    "]\n",
    "short_commute_cols = [\n",
    "    \"5 to 9 minutes\", \"10 to 14 minutes\", \"15 to 19 minutes\",\n",
    "    \"20 to 24 minutes\", \"25 to 29 minutes\"\n",
    "]\n",
    "medium_commute_cols = [\n",
    "    \"30 to 34 minutes\", \"35 to 39 minutes\", \"40 to 44 minutes\",\n",
    "    \"45 to 59 minutes\"\n",
    "]\n",
    "long_commute_cols = [\"60 to 89 minutes\", \"90 or more minutes\"]\n",
    "\n",
    "# Create new columns with the summed values\n",
    "df[\"No Commute\"] = df[no_commute_cols].sum(axis=1)\n",
    "df[\"Yes Commute (more than 5 minutes)\"] = df[yes_commute_cols].sum(axis=1)\n",
    "df[\"Short Commutes - Less than half-hour\"] = df[short_commute_cols].sum(axis=1)\n",
    "df[\"Medium Commutes - Half-hour to one hour\"] = df[medium_commute_cols].sum(axis=1)\n",
    "df[\"Long Commutes - More than one hour\"] = df[long_commute_cols].sum(axis=1)\n",
    "\n",
    "# Drop the original commute time columns\n",
    "columns_to_drop = no_commute_cols + yes_commute_cols\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Save the transformed dataframe to a new CSV file\n",
    "df.to_csv('Commute_Time_By_Top_50_Metro_Area_All_Years_Five_Buckets.csv', index=False)\n",
    "print(\"Transformation complete. New CSV file created.\")\n",
    "print(top_50_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b0858dfc-9fed-447c-81b2-35714d739390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage data has been saved to 'Commute_Time_By_Top_50_Metro_Area_All_Years_Five_Buckets_Percentage.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('Commute_Time_By_Top_50_Metro_Area_All_Years_Five_Buckets.csv')\n",
    "\n",
    "# Define the two separate categories\n",
    "commute_type_columns = [\n",
    "    'No Commute',\n",
    "    'Yes Commute (more than 5 minutes)'\n",
    "]\n",
    "\n",
    "commute_duration_columns = [\n",
    "    'Short Commutes - Less than half-hour',\n",
    "    'Medium Commutes - Half-hour to one hour',\n",
    "    'Long Commutes - More than one hour'\n",
    "]\n",
    "\n",
    "# Calculate percentages for commute type (No Commute vs Yes Commute)\n",
    "commute_type_total = df[commute_type_columns].sum(axis=1)\n",
    "for col in commute_type_columns:\n",
    "    df[f'{col} (%)'] = (df[col] / commute_type_total * 100).round(5)\n",
    "\n",
    "# Calculate percentages for commute duration (Short, Medium, Long)\n",
    "commute_duration_total = df[commute_duration_columns].sum(axis=1)\n",
    "for col in commute_duration_columns:\n",
    "    df[f'{col} (%)'] = (df[col] / commute_duration_total * 100).round(5)\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "df.to_csv('Commute_Time_By_Top_50_Metro_Area_All_Years_Five_Buckets_Percentage.csv', index=False)\n",
    "\n",
    "print(\"Percentage data has been saved to 'Commute_Time_By_Top_50_Metro_Area_All_Years_Five_Buckets_Percentage.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2dc9121e-4c56-422e-9e53-559a976eaf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'Final_Commute_Time.csv' has been created with the cleaned data.\n",
      "     Metro    Total  Year\n",
      "0  Atlanta  2232939  2010\n",
      "1  Atlanta  2715426  2018\n",
      "2  Atlanta  2588713  2023\n",
      "3  Atlanta  2533900  2015\n",
      "4  Atlanta  2264984  2011\n",
      "\n",
      "All columns in the updated file:\n",
      "['Metro', 'Total', 'Year', 'No Commute', 'Yes Commute (more than 5 minutes)', 'Short Commutes - Less than half-hour', 'Medium Commutes - Half-hour to one hour', 'Long Commutes - More than one hour', 'No Commute (%)', 'Yes Commute (more than 5 minutes) (%)', 'Short Commutes - Less than half-hour (%)', 'Medium Commutes - Half-hour to one hour (%)', 'Long Commutes - More than one hour (%)']\n",
      "              Metro    Total  Year  No Commute  \\\n",
      "0           Atlanta  2232939  2010       38502   \n",
      "1           Atlanta  2715426  2018       32705   \n",
      "2           Atlanta  2588713  2023       44118   \n",
      "3           Atlanta  2533900  2015       40298   \n",
      "4           Atlanta  2264984  2011       38588   \n",
      "..              ...      ...   ...         ...   \n",
      "595           Tampa  1334616  2018       26034   \n",
      "596           Tampa  1266517  2016       23810   \n",
      "597           Tampa  1151281  2012       21288   \n",
      "598  Virginia Beach   837120  2016       27703   \n",
      "599  Virginia Beach   781351  2011       17887   \n",
      "\n",
      "     Yes Commute (more than 5 minutes)  Short Commutes - Less than half-hour  \\\n",
      "0                              2194437                               1116005   \n",
      "1                              2682721                               1261517   \n",
      "2                              2544595                               1225249   \n",
      "3                              2493602                               1235801   \n",
      "4                              2226396                               1109374   \n",
      "..                                 ...                                   ...   \n",
      "595                            1308582                                735526   \n",
      "596                            1242707                                726918   \n",
      "597                            1129993                                695473   \n",
      "598                             809417                                530564   \n",
      "599                             763464                                512204   \n",
      "\n",
      "     Medium Commutes - Half-hour to one hour  \\\n",
      "0                                     814521   \n",
      "1                                    1032286   \n",
      "2                                     986755   \n",
      "3                                     922041   \n",
      "4                                     841960   \n",
      "..                                       ...   \n",
      "595                                   456128   \n",
      "596                                   408880   \n",
      "597                                   359009   \n",
      "598                                   233570   \n",
      "599                                   213611   \n",
      "\n",
      "     Long Commutes - More than one hour  No Commute (%)  \\\n",
      "0                                263911         1.72427   \n",
      "1                                388918         1.20442   \n",
      "2                                332591         1.70424   \n",
      "3                                335760         1.59035   \n",
      "4                                275062         1.70368   \n",
      "..                                  ...             ...   \n",
      "595                              116928         1.95067   \n",
      "596                              106909         1.87996   \n",
      "597                               75511         1.84907   \n",
      "598                               45283         3.30932   \n",
      "599                               37649         2.28924   \n",
      "\n",
      "     Yes Commute (more than 5 minutes) (%)  \\\n",
      "0                                 98.27573   \n",
      "1                                 98.79558   \n",
      "2                                 98.29576   \n",
      "3                                 98.40965   \n",
      "4                                 98.29632   \n",
      "..                                     ...   \n",
      "595                               98.04933   \n",
      "596                               98.12004   \n",
      "597                               98.15093   \n",
      "598                               96.69068   \n",
      "599                               97.71076   \n",
      "\n",
      "     Short Commutes - Less than half-hour (%)  \\\n",
      "0                                    50.85610   \n",
      "1                                    47.02379   \n",
      "2                                    48.15104   \n",
      "3                                    49.55887   \n",
      "4                                    49.82824   \n",
      "..                                        ...   \n",
      "595                                  56.20786   \n",
      "596                                  58.49472   \n",
      "597                                  61.54666   \n",
      "598                                  65.54891   \n",
      "599                                  67.08948   \n",
      "\n",
      "     Medium Commutes - Half-hour to one hour (%)  \\\n",
      "0                                       37.11754   \n",
      "1                                       38.47907   \n",
      "2                                       38.77847   \n",
      "3                                       36.97627   \n",
      "4                                       37.81717   \n",
      "..                                           ...   \n",
      "595                                     34.85666   \n",
      "596                                     32.90237   \n",
      "597                                     31.77090   \n",
      "598                                     28.85657   \n",
      "599                                     27.97918   \n",
      "\n",
      "     Long Commutes - More than one hour (%)  \n",
      "0                                  12.02636  \n",
      "1                                  14.49715  \n",
      "2                                  13.07049  \n",
      "3                                  13.46486  \n",
      "4                                  12.35459  \n",
      "..                                      ...  \n",
      "595                                 8.93547  \n",
      "596                                 8.60291  \n",
      "597                                 6.68243  \n",
      "598                                 5.59452  \n",
      "599                                 4.93134  \n",
      "\n",
      "[600 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_metro_name(name):\n",
    "    first_part = name.split('-')[0].strip()\n",
    "    words = first_part.split()\n",
    "    return ' '.join(words[:2]) if len(words) > 1 and words[1].istitle() else words[0]\n",
    "\n",
    "# Read the CSV file\n",
    "input_file = 'Commute_Time_By_Top_50_Metro_Area_All_Years_Five_Buckets_Percentage.csv'\n",
    "output_file = 'Final_Commute_Time.csv'\n",
    "\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Clean up the Metro Area name\n",
    "df['Metro'] = df['Metro Area'].apply(clean_metro_name)\n",
    "\n",
    "# Drop the original 'Metro Area' column if it exists\n",
    "if 'Metro Area' in df.columns:\n",
    "    df = df.drop(columns=['Metro Area'])\n",
    "\n",
    "# Reorder columns to put 'Metro' first\n",
    "cols = ['Metro'] + [col for col in df.columns if col != 'Metro']\n",
    "df = df[cols]\n",
    "\n",
    "# Save the updated DataFrame to the new CSV file\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"File '{output_file}' has been created with the cleaned data.\")\n",
    "\n",
    "# Display the first few rows to verify the changes\n",
    "print(df[['Metro', 'Total', 'Year']].head())\n",
    "\n",
    "# Display all column names to verify the structure\n",
    "print(\"\\nAll columns in the updated file:\")\n",
    "print(df.columns.tolist())\n",
    "print(df.head(600))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
